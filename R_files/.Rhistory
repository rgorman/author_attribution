sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], sum(error.v))
}
error.m
error.v <- append(error.v, error.m[12,12])
error.v <- append(error.v, error.m[12,12])
View(total.errors.l)
total.errors.l <-list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[j]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], sum(error.v))
}
intermediate.l <- list()
intermediate.l[[1]] <error.m[12,12]
intermediate.l[[1]] <-error.m[12,12]
intermediate.l[[2]] <-error.m[12,12]
intermediate.l[[3]] <-error.m[12,12]
total.errors.l <-list()
total.errors.l[[1]] <- c(feature.number.v[1], sapply(intermediate.l, sum)
)
total.errors.l
intermediate.l[[1]]
intermediate.l[[2]]
error.m[12,12]
sapply(intermediate.l, sum)
total.errors.l[[1]] <- c(feature.number.v[1], intermediate.l[[1]])
total.errors.l
total.errors.l[[1]] <- c(feature.number.v[1], intermediate.l)
total.errors.l
total.errors.l[[1]][3]
total.errors.l[[1]][3]
total.errors.l[[1]][[1]]
total.errors.l[[1]][[2]]
total.errors.l
total.errors.l <-list()
intermediate.l <- list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[j]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
# this isn't working: error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[1], intermediate.l)
}
total.error.l
total.errors.l
total.errors.l <-list()
intermediate.l <- list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[j]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
# this isn't working: error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], intermediate.l)
}
total.errors.l
save (total.errors.l, file="Rresults/iteration_list.R")
length(total.errors.l)
unlist(total.errors.l[[1]])
unlist(total.errors.l[[2]])
unlist(total.errors.l[[15]])
unlist(total.errors.l[[50]])
unlist(total.errors.l[[60]])
feature.df <- sorted.df[, 1:feature.number.v[60]]
feature.nimber.v[60]
feature.number.v[60]
feature.df <- sorted.df[, 1:feature.number.v[60]]
feature.df <- sorted.df[, 1:feature.number.v[20]]
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
sWord_classifier <- naiveBayes(training.data, training.classes)
holder <- predict(sWord_classifier, testing.data)
error.m <- errormatrix(testing.classes, holder)
error.m
error.v <- append(error.v, error.m[12,12])
i <- 1
error.v <- NULL
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
feature.df <- sorted.df[, 1:feature.number.v[1]]
i <- 1
error.v <- NULL
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[2]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[3]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[4]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[5]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[6]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[50]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[8]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[7]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[9]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[10]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
(s <-sum(error.v))
(r <- 1-(s/2800))
i <- 1
total.errors.l <-list()
intermediate.l <- list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[10]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], intermediate.l)
i <- 1
}
total.errors.l[[1]]
total.errors.l[[11]]
total.errors.l <-list()
intermediate.l <- list()
total.errors2.l <- list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[10]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], intermediate.l)
total.errors2.l[[j]] error.v <-
i <- 1
}
total.errors.l <-list()
intermediate.l <- list()
total.errors2.l <- list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[10]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], intermediate.l)
total.errors2.l[[j]] <- error.v
i <- 1
}
save (total.errors.l, file="Rresults/iteration_list.R")
save (total.errors2.l, file="Rresults/iteration_list2.R")

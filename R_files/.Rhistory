source('~/.active-rstudio-document', echo=TRUE)
4^4
4^3
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
library(languageR)
dbinom(59000, 1000000) 0.05885575
dbinom(59000, 1000000, 0.05885575)
dbinom(57000, 1000000, 0.05885575)
dbinom(58000, 1000000, 0.05885575)
dbinom(59000, 1000000, 0.05885575)
dbinom(588857, 1000000, 0.05885575)
dbinom(58885, 1000000, 0.05885575)
dbinom(3, 30, 0.05885575)
dbinom(3, 30, 0.33)
dbinom(3, 30, 33)
dbinom(3, 30, .85)
dbinom (1, 1000000, 0.0000082)
dbinom (1, 1000000, 0.0000082) + dbinom(1, 1000000, 0.0000082)
dbinom (1, 1000000, 0.0000082) + dbinom(0, 1000000, 0.0000082)
pbinom(1, 1000000, 0.0000082)
1 -pbinom(1, 1000000, 0.0000082)
pbinom(1, 1000000, 0.0000082)
pbinom(382, 1000000, 0.00013288)
1 - pbinom(382, 1000000, 0.00013288)
1 - pbinom(381, 1000000, 0.00013288)
n<- 1000
p <- 0.05885575
frequencies <- seq(25, 95, by = 1)
probability <- dbinom(frequencies, n, p)
plot (frequencies, probabilities, type ="h", xlab="frequency", ylab="probability of frequency")
plot (frequencies, probability, type ="h", xlab="frequency", ylab="probability of frequency")
plot (frequencies, probability,  xlab="frequency", ylab="probability of frequency")
plot (frequencies, probability, type ="h"  xlab="frequency", ylab="probability of frequency")
plot (frequencies, probability, type ="h",  xlab="frequency", ylab="probability of frequency")
n<- 1000
p <- 0.5
frequencies <- seq(25, 95, by = 1)
probability <- dbinom(frequencies, n, p)
plot (frequencies, probability, type ="h",  xlab="frequency", ylab="probability of frequency")
n<- 1000
p <- 0.05885575
frequencies <- seq(25, 95, by = 1)
probability <- dbinom(frequencies, n, p)
plot (frequencies, probability, type ="h",  xlab="frequency", ylab="probability of frequency")
n<- 1000
p <- 0.25
frequencies <- seq(20, 30, by = 1)
probability <- dbinom(frequencies, n, p)
plot (frequencies, probability, type ="h",  xlab="frequency", ylab="probability of frequency")
n<- 1000
p <- 0.025
frequencies <- seq(20, 30, by = 1)
probability <- dbinom(frequencies, n, p)
plot (frequencies, probability, type ="h",  xlab="frequency", ylab="probability of frequency")
n<- 1000
p <- 0.05885575
frequencies <- seq(25, 95, by = 1)
probability <- rbinom(frequencies, n, p)
plot (frequencies, probability, type ="h",  xlab="frequency", ylab="probability of frequency")
s <- 500
x <- xtabs(~ rbnom(s, n, p))
x <- xtabs(~ rbinom(s, n, p))
x
x <- xtabs(~ rbinom(s, n, p))/s
x
plot(as.numeric(names(x),x type ="h"))
plot(as.numeric(names(x),x, type ="h"))
plot(as.numeric(names(x),x, type ="h", xlim =c(0, 30)))
plot(as.numeric(names(x),x, type ="h", xlim =c(0, 30), xlac + "frequency"))
plot(as.numeric(names(x),x, type ="h", xlim =c(0, 30), xlab + "frequency"))
plot(as.numeric(names(x),x, type ="h", xlim =c(0, 30), xlab = "frequency"))
plot(as.numeric(names(x),x, type ="h", xlim =c(0, 30), xlab = "frequency", ylab = "sample probabbility"))
plot(as.numeric(names(x)),x, type ="h", xlim =c(0, 30), xlab = "frequency", ylab = "sample probabbility"))
plot(as.numeric(names(x)),x, type ="h", xlim =c(0, 30), xlab = "frequency", ylab = "sample probabbility")
havelaar
p <- havelaar$Frequency/n
qnts <- seq(.005, .995, by = .01)
plot (qbinom(qnts, n, p))
plot (qbinom(qnts, n, p), quantile(havelaar$Frequency, qnts))
qbinom(qnts, n, p)
quantile(havelaar$Frequency, qnts)
mean (havellar$Frequency)
mean (havelaar$Frequency)
mean (havelaar$Frequency / n)
mean (havelaar$Frequency)/ n
pbinom(4, 10, .5)
pbinom(5, 10, .5)
dbinom (1, 10, .5)
dbinom (1, 10, .5) + dbinom (2, 10, .5)
dbinom (1, 10, .5) + dbinom (2, 10, .5) + dbinom (3, 10, .5)
dbinom (1, 10, .5) + dbinom (2, 10, .5) + dbinom (3, 10, .5) + dbinom (4, 10, .5)
dbinom (1, 10, .5) + dbinom (2, 10, .5) + dbinom (3, 10, .5) + dbinom (4, 10, .5) + dbinom (0, 10, .5)
dbinom (1, 10, .5) + dbinom (2, 10, .5) + dbinom (3, 10, .5) + dbinom (4, 10, .5) + dbinom (0, 10, .5) + dbinom (5, 10, .5)
qbinom(.5, 10, .5)
qbinom(.25, 10, .5)
qbinom(.37, 10, .5)
qbinom(.38, 10, .5)
mean (havelaar$Frequency)/ n
qbinom (13, n, .01338)
qbinom (13, 1000, .01338)
pbinom (13, 1000, .01338)
pbinom (21, 1000, .01338)
dbinom (21, 1000, .01338)
dbinom (13, 1000, .01338)
dbinom (30, 1000, .01338)
pbinom (30, 1000, .01338)
qbinom(.38, 10, .5)
qbinom(.38, n, .5)
qbinom(.1, n, .5)
qbinom(.01, n, .5)
mean (havelaar$Frequency)/ n
qbinom(.01, n, .1338384)
qbinom(.02, n, .1338384)
qbinom(.92, n, .1338384)
qbinom(.992, n, .1338384)
qbinom(.992, 1000, .1338384)
qbinom(.992, 10000, .1338384)
qbinom(.992, 100000, .1338384)
qbinom(.992, 100000000, .1338384)
qbinom(.95, 100000000, .1338384)
qbinom(.95, 1000, .1338384)
pbinom (152, 1000, .01338)
qbinom(qnts, 1000, .01338)
quantile(havelaar$Frequency, qnts)
plot (qbinom(qnts, n, .01338), quantile(havelaar$Frequency. qnts))
plot (qbinom(qnts, n, .01338), quantile(havelaar$Frequency, qnts))
plot (qbinom(qnts, n, .01338))
plot (quantile(havelaar$Frequency, qnts))
plot (qbinom(qnts, n, .01338))
plot (qbinom(qnts, n, .01338), quantile(havelaar$Frequency, qnts))
dpois(10, 58856)
dpois(1000, 58856)
dpois(57000, 58856)
dpois(58000, 58856)
dpois(58800, 58856)
plot (dpois(58800, 58856))
havelaar.tab <- xtabs(~ havelaar$Frequency)
havelaar.tab
havelaar.probs <- xtabs(~ havelaar$Frequency)/ nrow(havelaar)
havelaar.probs
havelaar.probs <- xtabs(~ havelaar$Frequency)/ nrow(havelaar) round(havelaar.probs, 3)
havelaar.probs <- xtabs(~ havelaar$Frequency)/ nrow(havelaar) )
havelaar.probs <- xtabs(~ havelaar$Frequency)/ nrow(havelaar)
round (havelaar.probs, 3)
havelaar.probs <- round (havelaar.probs, 3)
sum (havelaar.probs)
plot(as.numeric(names(havelaar.probs)))
plot(as.numeric(names(havelaar.probs)), havelaar.probs)
havelaar.probs <- xtabs(~ havelaar$Frequency)/ nrow(havelaar)
sum (havelaar.probs)
plot(as.numeric(names(havelaar.probs)), havelaar.probs)
plot(as.numeric(names(havelaar.probs)), havelaar.probs, xlim=c(0, 40))
plot(as.numeric(names(havelaar.probs)), havelaar.probs, xlim=c(0, 40), type = "h")
plot (counts)
counts <- 0:42
plot (counts)
plot (counts, dbinom (counts, 1000, .0134))
plot (counts, dbinom (counts, 1000, .0134) type = "h")
plot (counts, dbinom (counts, 1000, .0134), type = "h")
lambda <- 1000*.0134
plot (dpois(counts, lambda))
plot (dpois(counts, lambda), type = "h")
x <- seq(-4, 4, 0.1)
y <- dnorm(x)
plot (x, y)
plot (x, y, xlab="x", ylab="density", ylim = c(0, 0.8), type ="l")
pt(-3, 2)
pt(-3, 20)
27269 %% 40
27240/40
alice [1:10]
alice <- tolower(alice)
wonderland <- data.frame(word = alice[1:27240], chunk = cut (1:27240, breaks 40, labels = F))
wonderland <- data.frame(word = alice[1:27240], chunk = cut (1:27240, breaks = 40, labels = F))
wonderland [1:5,]
wonderland$alice <- wonderland$word == "alice"
wonderland [1:5,]
wonderland$hare <- wonderland$word == "hare"
wonderland$very <- wonderland$word == "very"
wonderland [1:5,]
sum (wonderland$alice)
countOfAlice <- tapply (wonderland$alice, wonderland$chunk, sum)
countOfAlice
countOfAlice.tab <- xtabs(~ countOfAlice)
countOfAlice.tab
countOfHare <-tapply(wonderland$hare, wonderland$chunk, sum)
countOfHare.tab <- xtabs(~ countOfHare)
countOfVery <- tapply (wonderland$very, wonderland$chunk, sum)
countOfVery.tab <- xtabs(~ countOfVery)
plot(countOfAlice.tab)
plot (countOfAlice)
plot (countOfAlice, type = "l")
plot (countOfAlice, type = "h")
plot (countOfHare, type = "h")
plot (countOfvery, type = "h")
plot (countOfVery, type = "h")
countOfAlice
countOfAlice.tab
tappy(countOfAlice.tab, sum)
tapply(countOfAlice.tab, sum)
sum(countOfAlice.tab)
aggregate(countOfAlice.tab, /40)
aggregate(countOfAlice.tab)/40
tapply(countOfAlice, sum)
tapply(as.numeric(names(countOfAlice)), sum)
plot (as.numeric(names(countOfAlice.tab)))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab), type = "h", xlim = c(0,18, ylim = c(0,9)))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab), type = "h", xlim = c(0,18), ylim = c(0,9)))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab), type = "h", xlim = c(0,18), ylim = c(0,9))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40), type = "h", xlim = c(0,18), ylim = c(0,9))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0,9))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0, .09))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0, .5))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0, 0.5))
density(ver)
density(ver$Frequency)
plot(density(ver$Frequency)
plot(density(ver$Frequency))
plot(density(ver$Ferquency))
plot(density(ver$Frequency))
head (ver)
ver$Frequency <- log(ver$Frequency)
plot(density(ver$Frequency))
log(255)
log (-.5)
exp (-.5)
qqnorm(rnorm(length(ver$Frequency), 4, 3))
abline(v+ qnorm(.025), col = "grey")
abline(v= qnorm(.025), col = "grey")
abline (h= qnorm(.025, 4, 3)col = "grey")
abline(h = qnorm(.025, 4, 3), col = "grey")
head(Ont)
head(durationsOnt)
head(ver)
ver.transp <- ver[ver$SemanticClass == "transparent",]$Frequency
head(ver.transp)
ver.opaque <- ver[ver$SemanticClass == "opaque",]$Frequency
ver.transp.d <- density(ver.transp)
ver.opaque.d <- density(ver.opaque)
ver.transp.d <- density(ver.transp)
ver.opaque.d <- density(ver.opaque)
xlimit = range(ver.trasp.d$x, ver.opaque.d$x)
ylimit = range(ver.transp.d$y, ver.opaque.d$y)
plot(ver.transp.d, lty=1, col ="black", xlab="ferquency", ylab="density", xlim = xlimit, main="")
lines(ver.opaque.d, col = "darkgrey")
ver.transp.d <- density(ver.transp)
ver.opaque.d <- density(ver.opaque)
xlimit = range(ver.trasp.d$x, ver.opaque.d$x)
xlimit = range(ver.transp.d$x, ver.opaque.d$x)
ylimit = range(ver.transp.d$y, ver.opaque.d$y)
plot(ver.transp.d, lty=1, col ="black", xlab="ferquency", ylab="density", xlim = xlimit, main="")
lines(ver.opaque.d, col = "darkgrey")
ks.test(jitter(ver.transp), jitter(ver.opaque))
bwplot(Frequency ~ Class | Complex, data=ratings)
library(lattice)
bwplot(Frequency ~ Class | Complex, data=ratings)
q
q()
library(XML)
source("code/corpusFunctions.R")
input.dir <- "data/relationPosFiles"
files.v <- dir(path=input.dir, pattern=".*xml")
input.dir
library(stylo)
stylo.default.settings()
setwd("C:/authorship_attribution_working/R_files")
attach (what="Rresults/Naive_Bayes_predictions/list_of_classifiers.R")
ls
ls ()
x <- attach (what="Rresults/Naive_Bayes_predictions/list_of_classifiers.R")
str(x)
x <- attach ("Rresults/Naive_Bayes_predictions/list_of_classifiers.R")
x <- 1/1
x <- 1/12
(aeschy <- x/25)
(athen <- x/22)
(diod <- x/13)
(hdt <- x/16)
(hesiod <- x /10)
(iliad <- x/74)
(lysias <- x/6)
(odyssey <- x/44)
(plut <- x/11)
(plyb <- x/14)
(soph <- x/27)
(thuc <- x/12)
setwd("C:/authorship_attribution_working/R_files/Rresults/Naive_Bayes_predictions")
load ("list_of_classifiers.R")
str(sW.classifier.l)
str(sW.classifier.l[[1]])
load(rawPredictions.R)
load("rawPredictions.R")
sWord_predictions_raw.l[[1]]
sWord_predictions_raw.l[[2]]
sWord_predictions_raw.l[[3]]
sWord_predictions_raw.l[[4]]
sWord_predictions_raw.l[[5]]
setwd("C:/authorship_attribution_working/R_files")
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/rel_file"
files.v <- dir(path=input.dir, pattern=".*xml")
book.freqs.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.data.l <- getSwordChunkMaster(doc.object, 2000)
book.freqs.l[[files.v[i]]] <-chunk.data.l
}
summary(book.freqs.l)
freqs.l <- lapply(book.freqs.l, my.apply)
summary(freqs.l)
freqs.df <- do.call(rbind, freqs.l)
dim(freqs.df)
head(freqs.df)
bookids.v <- gsub(".xml.\\d+", "", rownames(freqs.df))
book.chunk.ids <- paste(bookids.v, freqs.df$ID, sep="_")
freqs.df$ID <- book.chunk.ids
head(freqs.df)
result.t <- xtabs(Freq ~ ID+Var1, data=freqs.df)
dim(result.t)
final.df <- as.data.frame.matrix(result.t)
dim(final.df)
author.v <- gsub("_.+", "", rownames(final.df))
unique(author.v)
freq.means.v <- colMeans(final.df[, ])
keepers.v <- which(freq.means.v >=.001)
smaller.df <- final.df[, keepers.v]
dim(smaller.df)
prob.m <- read.csv (file="Rresults/Naive_Bayes_predictions/chunkSize2000/chunk_parameters3.csv")
library(e1071)
library (gmodels)
library(klaR)
testing.classes.l <- list()
sWord_predictions.l <- list()
sWord_predictions_raw.l <- list()
index.record.v <- NULL
err.matr.l <- list()
sW.classifier.l <- list()
i <- 1
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(smaller.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- smaller.df[testing.index.v, ]
training.data <- smaller.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# test the algorithm by using sWord_classifier to predict() the testing.data
#store results in list object
sWord_predictions.l[[i]] <- predict(sWord_classifier, testing.data)
# make a file of the raw probabilities
sWord_predictions_raw.l[[i]] <- predict(sWord_classifier, testing.data, type = "raw")
#make record of index vectors so we can identify the particular chunks
index.record.v <- append(index.record.v, testing.index.v)
#make record of testing_classes
testing.classes.l[[i]] <-testing.classes
#make list of error matrices
err.matr.l[[i]] <- errormatrix(testing.classes.l[[i]], sWord_predictions.l[[i]])
#collect the sWord_classifier objects
sW.classifier.l[[i]] <- sWord_classifier
}
a <- do.call(rbind, err.matr.l)
write.csv(a, file="Rresults/Naive_Bayes_predictions/error_matrix.csv")
my.list <- mapply(data.frame, sWord_predictions.l)
b <- do.call (rbind, my.list)
write.csv (b, file="Rresults/Naive_Bayes_predictions/predictions_made.csv")
my.list <- mapply(data.frame, sWord_predictions_raw.l)
c <- do.call (rbind, my.list)
write.csv (c, file="Rresults/Naive_Bayes_predictions/raw_predictions_made.csv")
my.list <- mapply(data.frame, testing.classes.l)
d <- do.call (rbind, my.list)
write.csv (d, file="Rresults/Naive_Bayes_predictions/right_answers.csv")
save(sW.classifier.l, file="Rresults/Naive_Bayes_predictions/list_of_classifiers.R")
head(d)
levs <- levels(sWord_predictions.l[[11]])
pred.author.l <- list()
levs <- NULL
i <- 1
for (i in i:100) {
levs <- levels(sWord_predictions.l[[i]])
pred.author.l[[i]] <- levs[a[i,]]
}
pred.author.t <- do.call(rbind, pred.author.l)
pred.author.l[[1]]
pred.author.l[[2]]
pred.author.l[[3]]
pred.author.l[[4]]
pred.author.l[[5]]
pred.author.l[[6]]
pred.author.l[[7]]
sWord_predictions.l[[1]]
index.record.m <- matrix(index.record.v, nrow=100, ncol=28, byrow=TRUE)
intex.record.m[1,]
index.record.m[1,]
index.record.v[1:10]
index.record.v[1:28]
index.record.v[1:29]
index.record.m[2,]
write.csv(index.record.m, file="Rresults/Naive_Bayes_predictions/index_matrix.csv")
write.csv(index.record.v, file="Rresults/Naive_Bayes_predictions/index_vector.csv")

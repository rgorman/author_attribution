plot (countOfVery, type = "h")
countOfAlice
countOfAlice.tab
tappy(countOfAlice.tab, sum)
tapply(countOfAlice.tab, sum)
sum(countOfAlice.tab)
aggregate(countOfAlice.tab, /40)
aggregate(countOfAlice.tab)/40
tapply(countOfAlice, sum)
tapply(as.numeric(names(countOfAlice)), sum)
plot (as.numeric(names(countOfAlice.tab)))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab), type = "h", xlim = c(0,18, ylim = c(0,9)))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab), type = "h", xlim = c(0,18), ylim = c(0,9)))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/sum(countOfAlice.tab), type = "h", xlim = c(0,18), ylim = c(0,9))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40), type = "h", xlim = c(0,18), ylim = c(0,9))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0,9))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0, .09))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0, .5))
plot (as.numeric(names(countOfAlice.tab)), countOfAlice.tab/40, type = "h", xlim = c(0,18), ylim = c(0, 0.5))
density(ver)
density(ver$Frequency)
plot(density(ver$Frequency)
plot(density(ver$Frequency))
plot(density(ver$Ferquency))
plot(density(ver$Frequency))
head (ver)
ver$Frequency <- log(ver$Frequency)
plot(density(ver$Frequency))
log(255)
log (-.5)
exp (-.5)
qqnorm(rnorm(length(ver$Frequency), 4, 3))
abline(v+ qnorm(.025), col = "grey")
abline(v= qnorm(.025), col = "grey")
abline (h= qnorm(.025, 4, 3)col = "grey")
abline(h = qnorm(.025, 4, 3), col = "grey")
head(Ont)
head(durationsOnt)
head(ver)
ver.transp <- ver[ver$SemanticClass == "transparent",]$Frequency
head(ver.transp)
ver.opaque <- ver[ver$SemanticClass == "opaque",]$Frequency
ver.transp.d <- density(ver.transp)
ver.opaque.d <- density(ver.opaque)
ver.transp.d <- density(ver.transp)
ver.opaque.d <- density(ver.opaque)
xlimit = range(ver.trasp.d$x, ver.opaque.d$x)
ylimit = range(ver.transp.d$y, ver.opaque.d$y)
plot(ver.transp.d, lty=1, col ="black", xlab="ferquency", ylab="density", xlim = xlimit, main="")
lines(ver.opaque.d, col = "darkgrey")
ver.transp.d <- density(ver.transp)
ver.opaque.d <- density(ver.opaque)
xlimit = range(ver.trasp.d$x, ver.opaque.d$x)
xlimit = range(ver.transp.d$x, ver.opaque.d$x)
ylimit = range(ver.transp.d$y, ver.opaque.d$y)
plot(ver.transp.d, lty=1, col ="black", xlab="ferquency", ylab="density", xlim = xlimit, main="")
lines(ver.opaque.d, col = "darkgrey")
ks.test(jitter(ver.transp), jitter(ver.opaque))
bwplot(Frequency ~ Class | Complex, data=ratings)
library(lattice)
bwplot(Frequency ~ Class | Complex, data=ratings)
q
q()
library(XML)
source("code/corpusFunctions.R")
input.dir <- "data/relationPosFiles"
files.v <- dir(path=input.dir, pattern=".*xml")
input.dir
library(stylo)
stylo.default.settings()
setwd("C:/authorship_attribution_working/R_files")
relPos <- read.csv(file="Rresults/relPos544.csv")
View(relPos)
mean(relPos[,1])
mean(relPos[,2])
sd(relPos[,2])
var(relPos[,2])
sqrt(var(relPos[,2]))
rawErrors.m <- read.csv(file="rawErrors.scv", header=FALSE)
rawErrors.m <- read.csv(file="rawErrors.csv", header=FALSE)
View(rawErrors.m)
test <- rawErrors.m[1:2, ]
View(test)
order(test[2, 3:14])
order(test[2, 3:14], decerasing=TRUE)
order(test[2, 3:14], decreasing=TRUE)
test[1:2, 1:2]
test[1:2, order(test[2, 3:14], decreasing=TRUE)]
c(test[1:2, 1:2], test[1:2, order(test[2, 3:14], decreasing=TRUE)])
cbind(test[1:2, 1:2], test[1:2, order(test[2, 3:14], decreasing=TRUE))
cbind(test[1:2, 1:2], test[1:2, order(test[2, 3:14], decreasing=TRUE)
)
test[1:2, order(test[2, 3:14], decreasing=TRUE)]
author <- test[1:2, 1:2]
scores <- test[1:2, order(test[2, 3:14], decreasing=TRUE)]
cbind(author, scores)
reordered.m <- cbind(author, scores)
View(reordered.m)
rows <- seq(3, 5253, 2)
length(rows)
i <- 1
test <- raw.Errors.m[rows[i]:rows[i+1]]
test <- rawErrors.m[rows[i]:rows[i+1]]
test <- rawErrors.m[rows[i]:rows[i+1], 1:2]
View(test)
test <- rawErrors.m[rows[i]:rows[i+1], 1:2]
(test <- rawErrors.m[rows[i]:rows[i+1], 1:2])
(test <- rawErrors.m[rows[i]:rows[i+0], 1:2])
(test <- rawErrors.m[rows[i]:rows[i+1], 1:2])
j <- i+1
(test <- rawErrors.m[rows[i]:rows[j], 1:2])
(test <- rawErrors.m[rows[i]:rows[4], 1:2])
(test <- rawErrors.m[rows[3]:rows[4], 1:2])
i <- 1
rawErrors[i, 1:2]
rawErrors.m[i, 1:2]
rawErrors.m[i:(i+1), 1:2]
test <- rawErrors.m[i:(i+1), 1:2]
View(test)
test <- rawErrors.m[rows[i]:rows[(i+1)], 1:2]
View(test)
test <- rawErrors.m[rows[i]:rows[i], 1:2]
View(test)
rawErrors.m <- read.csv(file="rawErrors.csv", header=FALSE)
View(rawErrors.m)
test <- rawErrors.m[1:2, order(rawErrors.m[2, ], decreasing=TRUE)]
View(test)
order(rawErrors.m[2, ], decreasing=TRUE)
order(rawErrors.m[2, ], decreasing=FALSE)
test <- rawErrors.m[1:2, order(rawErrors.m[2, 1:13], decreasing=TRUE)]
View(test)
test[1:2, order(test[2, 3:14], decreasing=TRUE)]
test <- rawErrors.m[1:2, ]
test.sort <- test[]
order(test[2, 3:14], decreasing=TRUE)
test <- rawErrors.m[1:2, ]
View(test)
rawErrors.m [1:2,]
order(rawErrors.m [1:2,])
(rawErrors.m [1:2,])
rawErrors.m[1:2, order(rawErrors.m [2,])
]
rawErrors.m[1:2, order(rawErrors.m [2,])]
a <- rawErrors.m[1:2, order(rawErrors.m [2,])]
b <- rawErrors.m[3:4, order(rawErrors.m [4,])]
rbind(a, b)
rawErrors.m <- read.csv(file="rawErrors.csv", header=FALSE, stingsAsFactors=FALSE)
rawErrors.m <- read.csv(file="rawErrors.csv", header=FALSE, stringsAsFactors=FALSE)
View(rawErrors.m)
a <- rawErrors.m[1:2, order(rawErrors.m [2,])]
b <- rawErrors.m[3:4, order(rawErrors.m [4,])]
rbind(a, b)
b
b <- rawErrors.m[3:4, order(rawErrors.m [4,])]
b
a
rawErrors.m[2, order(rawErrors[2,])]
rawErrors.m[2, order(rawErrors.m[2,])]
rawErrors.m[2, order(rawErrors.m[2,], decreasing=TRUE)]
as.Vecto(rawErrors.m[2,])
as.Vector(rawErrors.m[2,])
as.vector(rawErrors.m[2,])
vector(rawErrors.m[2,])
b
a
order(rawErrors.m[1,])
order(rawErrors.m[2,])
sort(rawErrors.m[2,])
unlist(rawErrors[2,])
unlist(rawErrors.m[2,])
as.numeric(unlist(rawErrors.m[2,]))
order(as.numeric(unlist(rawErrors.m[2,])))
sort(as.numeric(unlist(rawErrors.m[2,])))
sort(as.numeric(unlist(rawErrors.m[2,])),decreasing=TRUE)
d <-sort(as.numeric(unlist(rawErrors.m[2,])),decreasing=TRUE)
matrix(d, rawErrors.m[1, order(as.numeric(unlist(rawErrors.m[2,])), decreasing=TRUE)] rows=2, cols=13)
matrix(d, rawErrors.m[1, order(as.numeric(unlist(rawErrors.m[2,])), decreasing=TRUE)], rows=2, cols=13)
matrix(d, rows=2, cols=13)
matrix(d, nrow=2, ncol=13)
e <- order(as.numeric(unlist(rawErrors.m[2,])),decreasing=TRUE)t
e <- order(as.numeric(unlist(rawErrors.m[2,])),decreasing=TRUE)
matrix(d, rawErrors.m[1,e] nrow=2, ncol=13)
matrix(d, rawErrors.m[1,e], nrow=2, ncol=13)
matrix(d, rawErrors.m[1,e], nrow=2, ncol=13, byrow=TRUE)
rawErrors.m[1,e]
raw <- read.csv(file="rawErrors.csv", header=FALSE, as.is=TRUE)
raw[2,]
sort(raw[2,])
unlist(raw[2,])
as.numeric(unlist(raw[2,]))
sort(as.numeric(unlist(raw[2,])))
sort(as.numeric(unlist(raw[2,])), decreasing=TRUE)
order(as.numeric(unlist(raw[2,])), decreasing=TRUE)
raw[1, order(as.numeric(unlist(raw[2,])), decreasing=TRUE)]
raw[1, order(as.numeric(unlist(raw[2,])), decreasing=TRUE)]
author <- raw[1, order(as.numeric(unlist(raw[2,])), decreasing=TRUE)]
df{1,} <- data.frame(author, stringsAsFactors=FALSE)
df[1,] <- data.frame(author, stringsAsFactors=FALSE)
df <- data.frame(author, stringsAsFactors=FALSE)
df
sort(as.numeric(unlist(raw[2,])), decreasing=TRUE)
df[2,] <- sort(as.numeric(unlist(raw[2,])), decreasing=TRUE)
df
odds <- seq(3, 5253, 2)
evens <- seq(2, 5254, 2)
evens <- seq(4, 5254, 2)
sort(as.numeric(unlist(raw[odds[1],])), decreasing=TRUE)
sort(as.numeric(unlist(raw[evens[1],])), decreasing=TRUE)
order(as.numeric(unlist(raw[evens[1],])), decreasing=TRUE)
author <- raw[3, order(as.numeric(unlist(raw[4,])), decreasing=TRUE)]
df[3,]<- author
df
df[4,]<- sort(as.numeric(unlist(raw[4,])), decreasing=TRUE)
df
odds <- seq(5, 5253, 2)
evens <- seq(6, 5254, 2)
length(evens)
length(odds)
i <- 1
sort(as.numeric(unlist(raw[evens[1],])), decreasing=TRUE)
order(as.numeric(unlist(raw[evens[1],])), decreasing=TRUE)
author <- raw[odds[i], order(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)]
author
author <- raw[odds[i], order(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)]
df[odds[i],]<- author
df[evens[i],]<- sort(as.numeric(unlist(evens[i,])), decreasing=TRUE)
sort(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)
scores <- sort(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)
df[evens[i],]<- scores
df
odds <- seq(7, 5253, 2)
evens <- seq(8, 5254, 2)
length(evens)
length(odds)
for (i in 1:length(evens)) {
scores <- sort(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)
order(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)
author <- raw[odds[i], order(as.numeric(unlist(raw[evens[i],])), decreasing=TRUE)]
df[odds[i],]<- author
df[evens[i],]<- scores
}
View(df)
write.csv (df, file="orderedRawErrors.csv")
sort(as.numeric(unlist(raw[2,])), decreasing=TRUE)
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/rel_pos_files"
files.v <- dir(path=input.dir, pattern=".*xml")
files.v
book.freqs.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.data.l <- getSwordChunkMaster(doc.object, 2000)
book.freqs.l[[files.v[i]]] <-chunk.data.l
}
summary(book.freqs.l)
freqs.l <- lapply(book.freqs.l, my.apply)
freqs.df <- do.call(rbind, freqs.l)
dim(freqs.df)
bookids.v <- gsub(".xml.\\d+", "", rownames(freqs.df))
book.chunk.ids <- paste(bookids.v, freqs.df$ID, sep="_")
freqs.df$ID <- book.chunk.ids
result.t <- xtabs(Freq ~ ID+Var1, data=freqs.df)
dim(result.t)
final.df <- as.data.frame.matrix(result.t)
author.v <- gsub("_.+", "", rownames(final.df))
unique(author.v)
freq.means.v <- colMeans(final.df[, ])
keepers.v <- which(freq.means.v >=.00016)
smaller.df <- final.df[, keepers.v]
dim(smaller.df)
keepers.v <- which(freq.means.v >=.00015)
smaller.df <- final.df[, keepers.v]
dim(smaller.df)
sorted.df <- smaller.df[, order(colMeans(smaller.df), decreasing=TRUE) ]
View(sorted.df)
summary(freqs.l)
summary(book.freqs.l)
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/rel_pos_files"
files.v <- dir(path=input.dir, pattern=".*xml")
book.freqs.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.data.l <- getSwordChunkMaster(doc.object, 2000)
book.freqs.l[[files.v[i]]] <-chunk.data.l
}
summary(book.freqs.l)
cite.l <- list()
cite.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.size <-2000
sword.cite <- getNodeSet(doc.object, "//sWord/@cite")
cite.v <- paste(sword.cite, collapse=NULL)
divisor <- length(cite.v)/chunk.size
max.length <- length(cite.v)/divisor
x <- seq_along(cite.v)
cite.l[[i]] <- split(cite.v, ceiling(x/max.length))
}
df <- matrix(nrow=1, ncol=3)
colnames(df) <- c("First", "Last", "Size")
i <- 1
holder.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
df <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
cite.param.m <-df[-1,]
write.csv (cite.param.m, file="Rresults/chunk_parameters4.csv")
x <- 1/11
(aeschy <- x/25)
(athen <- x/22)
# diodorus
(diod <- x/13)
(hdt <- x/16)
(hesiod <- x /10)
summary(book.freqs.l)
(iliad <- x/62)
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/rel_file"
files.v <- dir(path=input.dir, pattern=".*xml")
input.dir <- "sWord_input/stat_files/rel_file"
files.v <- dir(path=input.dir, pattern=".*xml")
files.v <- dir(path=input.dir, pattern=".*xml")
input.dir <- "sWord_input/stat_files/rel__pos_file"
files.v <- dir(path=input.dir, pattern=".*xml")
input.dir <- "sWord_input/stat_files/rel_pos_file"
files.v <- dir(path=input.dir, pattern=".*xml")
input.dir <- "sWord_input/stat_files/rel_pos_files"
files.v <- dir(path=input.dir, pattern=".*xml")
cite.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.size <-2000
sword.cite <- getNodeSet(doc.object, "//sWord/@cite")
cite.v <- paste(sword.cite, collapse=NULL)
divisor <- length(cite.v)/chunk.size
max.length <- length(cite.v)/divisor
x <- seq_along(cite.v)
cite.l[[i]] <- split(cite.v, ceiling(x/max.length))
}
summary(cite.l)
df <- matrix(nrow=1, ncol=3)
colnames(df) <- c("First", "Last", "Size")
i <- 1
holder.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
df <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
cite.param.m <-df[-1,]
write.csv (cite.param.m, file="Rresults/chunk_parameters4.csv")
summary(cite.l)
(aeschy <- x/25)
x <- 1/11
(aeschy <- x/25)
(athen <- x/22)
(diod <- x/13)
(hdt <- x/16)
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/stat_files/rel_pos_files"
files.v <- dir(path=input.dir, pattern=".*xml")
cite.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.size <-2000
sword.cite <- getNodeSet(doc.object, "//sWord/@cite")
cite.v <- paste(sword.cite, collapse=NULL)
divisor <- length(cite.v)/chunk.size
max.length <- length(cite.v)/divisor
x <- seq_along(cite.v)
cite.l[[i]] <- split(cite.v, ceiling(x/max.length))
}
summary(cite.l)
df <- matrix(nrow=1, ncol=3)
colnames(df) <- c("First", "Last", "Size")
i <- 1
holder.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
df <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
cite.param.m <-df[-1,]
write.csv (cite.param.m, file="Rresults/chunk_parameters4.csv")
x <- 1/11
(aeschy <- x/25)
(athen <- x/22)
(diod <- x/13)
(hdt <- x/16)
(hesiod <- x /10)
(hesiod <- x /10)
summary(cite.l)
(iliad <- x/62)
(odyssey <- x/50)
(plut <- x/11)
(plyb <- x/14)
(soph <- x/27)
(thuc <- x/12)
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/stat_files/rel_pos_files"
files.v <- dir(path=input.dir, pattern=".*xml")
cite.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.size <-2000
sword.cite <- getNodeSet(doc.object, "//sWord/@cite")
cite.v <- paste(sword.cite, collapse=NULL)
divisor <- length(cite.v)/chunk.size
max.length <- length(cite.v)/divisor
x <- seq_along(cite.v)
cite.l[[i]] <- split(cite.v, ceiling(x/max.length))
}
summary(cite.l)
df <- matrix(nrow=1, ncol=3)
colnames(df) <- c("First", "Last", "Size")
i <- 1
holder.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
df <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
cite.param.m <-df[-1,]
write.csv (cite.param.m, file="Rresults/chunk_parameters5.csv")
library(XML)
source("code/corpusFunctions.R")
input.dir <- "sWord_input/rel_pos_files"
files.v <- dir(path=input.dir, pattern=".*xml")
book.freqs.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE)
chunk.data.l <- getSwordChunkMaster(doc.object, 2000)
book.freqs.l[[files.v[i]]] <-chunk.data.l
}
summary(book.freqs.l)
freqs.l <- lapply(book.freqs.l, my.apply)
freqs.df <- do.call(rbind, freqs.l)
dim(freqs.df)
bookids.v <- gsub(".xml.\\d+", "", rownames(freqs.df))
book.chunk.ids <- paste(bookids.v, freqs.df$ID, sep="_")
freqs.df$ID <- book.chunk.ids
result.t <- xtabs(Freq ~ ID+Var1, data=freqs.df)
dim(result.t)
final.df <- as.data.frame.matrix(result.t)
author.v <- gsub("_.+", "", rownames(final.df))
unique(author.v)
length(author.v)
freq.means.v <- colMeans(final.df[, ])
keepers.v <- which(freq.means.v >=.00015)
smaller.df <- final.df[, keepers.v]
dim(smaller.df)
sorted.df <- smaller.df[, order(colMeans(smaller.df), decreasing=TRUE) ]
View(sorted.df)
prob.m <- read.csv (file="Rresults/Naive_Bayes_predictions/chunkSize2000/chunk_parameters5.csv")
library(e1071)
library (gmodels)
library(klaR)
feature.number.v <- seq(2, 500, 2)
total.errors.l <-list()
intermediate.l <- list()
total.errors2.l <- list()
i <- 1
j <- 1
for (j in j:250) {
error.v <- NULL
feature.df <- sorted.df[, 1:feature.number.v[j]]
for (i in i:100) {
#create vector of random integers = 10% of obs in smaller.df
testing.index.v <- sample (seq (1, nrow(feature.df)), 28, prob=prob.m$prob)
#create training and testing data matrices using testing.index.v and its inverse
testing.data <- feature.df[testing.index.v, ]
training.data <- feature.df[-testing.index.v, ]
#create vectors of factors giving classes (here = authors) of each row in testing.data and training.data
training.classes <- as.factor(author.v[-testing.index.v])
testing.classes <- as.factor(author.v[testing.index.v])
#train the algorithm using training.data and training classes
sWord_classifier <- naiveBayes(training.data, training.classes)
# run classification algorithm and put results in object
holder <- predict(sWord_classifier, testing.data)
# create errror matrix of results and put into object
error.m <- errormatrix(testing.classes, holder)
error.v <- append(error.v, error.m[12,12])
intermediate.l[[i]] <-error.m[12,12]
}
# save grand total of errors for each iteration into list object along with number of features
total.errors.l[[j]] <- c(feature.number.v[j], intermediate.l)
total.errors2.l[[j]] <- error.v
i <- 1
}
save (total.errors.l, file="Rresults/iteration_list_sept13.R")
save (total.errors2.l, file="Rresults/iteration_list2_sept13.R")
errors.m <- read.csv(file="Rresults/rel_pos_iterationTest_sept13.csv")
names(errors.m)
plot(errors.m$variable_quantity, errors.m$sucess_rate)
plot(errors.m$variable_quantity, errors.m$success_rate)
